{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tflearn\n",
    "from sklearn.utils import shuffle\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "tflearn.activations\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_and_predict(net, data, label):\n",
    "    model = tflearn.DNN(net, tensorboard_verbose=3, tensorboard_dir='./learn_logs/')\n",
    "    model.fit({'input': data[\"X_train\"]}, {'target': data[\"y_train\"]},\n",
    "              validation_set=({'input': data[\"X_test\"]}, {'target': data[\"y_test\"]}),\n",
    "              n_epoch=100,\n",
    "              snapshot_step=1000,\n",
    "              show_metric=True,\n",
    "              run_id=label,\n",
    "              batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def task_1(activaction_='tanh'):\n",
    "    network = input_data(shape=[None, 28, 28, 1], name='input')\n",
    "    network = fully_connected(network, n_units=1024 * 4, activation='tanh')\n",
    "    network = fully_connected(network, n_units=1024 * 2, activation=activaction_)\n",
    "    network = fully_connected(network, n_units=1024 * 1, activation=activaction_)\n",
    "    network = fully_connected(network, 10, activation='softmax')\n",
    "    network = regression(network, optimizer='sgd', learning_rate=0.001, loss='categorical_crossentropy', name='target')\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def task_2(activaction_='tanh'):\n",
    "    network = input_data(shape=[None, 28, 28, 1], name='input')\n",
    "    network = conv_2d(network, nb_filter=3, filter_size=3, strides=1, activation='relu')\n",
    "    network = fully_connected(network, 1024 * 4, activation=activaction_)\n",
    "    network = fully_connected(network, 1024 * 2, activation=activaction_)\n",
    "    network = fully_connected(network, 1024 * 1, activation=activaction_)\n",
    "    network = fully_connected(network, 10, activation='softmax')\n",
    "    network = regression(network, optimizer='adam', learning_rate=0.001, loss='categorical_crossentropy', name='target')\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def task_3():\n",
    "    network = input_data(shape=[None, 28, 28, 1], name='input')\n",
    "\n",
    "    network = conv_2d(network, nb_filter=3, filter_size=3, strides=1, activation='relu')\n",
    "    network = max_pool_2d(network, kernel_size=3, strides=2)\n",
    "\n",
    "    network = conv_2d(network, nb_filter=3, filter_size=3, strides=1, activation='relu')\n",
    "    network = max_pool_2d(network, kernel_size=3, strides=2)\n",
    "\n",
    "    network = fully_connected(network, 1024 * 4, activation='relu')\n",
    "    network = fully_connected(network, 1024 * 2, activation='relu')\n",
    "    network = fully_connected(network, 1024 * 1, activation='relu')\n",
    "\n",
    "    network = fully_connected(network, 10, activation='softmax')\n",
    "    network = regression(network, optimizer='adam', learning_rate=0.01, loss='categorical_crossentropy', name='target')\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dop_task_1():\n",
    "    network = input_data(shape=[None, 28, 28, 1], name='input')\n",
    "\n",
    "    network = conv_2d(network, nb_filter=3, filter_size=3, strides=1, activation='relu')\n",
    "    network = max_pool_2d(network, kernel_size=3, strides=2)\n",
    "\n",
    "    network = conv_2d(network, nb_filter=3, filter_size=3, strides=1, activation='relu')\n",
    "    network = max_pool_2d(network, kernel_size=3, strides=2)\n",
    "\n",
    "    network = fully_connected(network, 1024 * 4, activation='relu')\n",
    "    network = dropout(network, 0.8)\n",
    "    network = fully_connected(network, 1024 * 2, activation='relu')\n",
    "    network = dropout(network, 0.8)\n",
    "    network = fully_connected(network, 1024 * 1, activation='relu')\n",
    "\n",
    "    network = fully_connected(network, 10, activation='softmax')\n",
    "    network = regression(network, optimizer='adam', learning_rate=0.007, loss='categorical_crossentropy', name='target')\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load(\"notMNIST.pickle\", allow_pickle=True)\n",
    "\n",
    "X, Y = data['test_dataset'], data['test_labels']\n",
    "X_val, y_val = data['valid_dataset'][:1000], data['valid_labels'][:1000]\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle \n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split data on train and test\n",
    "X, Y = shuffle(X, Y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=42, test_size=0.2, stratify=Y)\n",
    "del X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape([-1, 28, 28, 1])\n",
    "y_train = dense_to_one_hot(y_train, 10)\n",
    "\n",
    "X_test = X_test.reshape([-1, 28, 28, 1])\n",
    "y_test = dense_to_one_hot(y_test)\n",
    "\n",
    "X_val = X_val.reshape([-1, 28, 28, 1])\n",
    "y_val = dense_to_one_hot(y_val)\n",
    "\n",
    "data_dict = {\n",
    "    \"X_train\": X_train,\n",
    "    \"y_train\": y_train,\n",
    "    \"X_test\": X_test,\n",
    "    \"y_test\": y_test,\n",
    "    \"X_val\": X_val,\n",
    "    \"y_val\": y_val\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for activation in ['sigmoid', 'relu', 'tanh']:\n",
    "    fit_and_predict(task_1(activation), data_dict, \"_\".join([\"task_1\", activation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_and_predict(task_2(), data_dict, \"_\".join([\"task_2\", \"tanh\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_and_predict(task_3(), data_dict, \"_\".join([\"task_3\", \"\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_and_predict(dop_task_1(), data_dict, \"_\".join([\"dop_task\", \"\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_and_predict(task_3(), data_dict, \"_\".join([\"task_3_withoutCUDA\", \"\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
